---
- hosts: sparkSARH7
  vars:
#   download_url: http://download.oracle.com/otn-pub/java/jdk/8u5-b13/jdk-8u5-linux-x64.tar.gz
    download_url: http://download.oracle.com/otn-pub/java/jdk/8u181-b13/96a7b8442fe848ef90c96a2fad6ed6d1/jdk-8u181-linux-x64.tar.gz 
    download_folder: /opt
    java_name: "{{download_folder}}/jdk1.8.0_181"
    java_archive: "{{download_folder}}/jdk-8u181-linux-x64.tar.gz"
    java_home: /usr/java/jdk1.8.0_181

  become: yes
  become_method: sudo
  tasks:
    - name: install libselinux-python
      yum:
        name: libselinux-python
        state: present
    - name: create directory
      file:
        path: /usr/java
        state: directory
        owner: root
        group: root
        mode: 0755
#   - name: create dir1
#     file: 
#       path: /opt/oracle/jdk1.8.0_181
#       state: directory
#       owner: root
#       group: root
#       mode: 0755
    - name: check for java 8 download
      stat: 
        path: "{{ java_archive }}"    
      register: java8dl
    - debug:
        msg: "{{ java8dl.stat.exists }}"
   
    - name: download java 8
      get_url: url={{ download_url }} dest={{ java_archive }} headers="Cookie:' gpw_e24=http%3A%2F%2Fwww.oracle.com%2F; oraclelicense=accept-securebackup-cookie'" validate_certs=no owner=root group=root mode=744 
      when: java8dl.stat.exists == False
    - name: unpack java archive
#     file: state=directory path={{ java_name }} owner=root group=root recurse=yes
      unarchive:
        src: "{{ java_archive }}"
        dest: /usr/java/
        remote_src: yes
    - name: update alternatives
      command: alternatives --install /usr/bin/java java {{ java_home }}/bin/java 50
    - name: check if already downloaded
      stat: 
        path: /opt/spark-2.3.1-bin-hadoop2.7.tgz
      register: spark_dl
    - debug: 
        msg: "{{ spark_dl.stat.exists }}"
    - name: download spark standalone
      get_url:
        url:  https://archive.apache.org/dist/spark/spark-2.3.1/spark-2.3.1-bin-hadoop2.7.tgz
        dest: /opt
      when: spark_dl.stat.exists == False
#   - name: copy local file to vm
#     copy:
#       src: ./files/sshpass-1.06-1.el7.x86_64.rpm
#       dest: /opt
#       owner: root
#       group: root
    - name: extract spark download
      unarchive:
        src: /opt/spark-2.3.1-bin-hadoop2.7.tgz
        dest: /opt
        remote_src: yes
