---
- hosts: sparkSARH7
  vars:
#   download_url: http://download.oracle.com/otn-pub/java/jdk/8u5-b13/jdk-8u5-linux-x64.tar.gz
    download_url: http://download.oracle.com/otn-pub/java/jdk/8u181-b13/96a7b8442fe848ef90c96a2fad6ed6d1/jdk-8u181-linux-x64.tar.gz 
    download_folder: /opt
    java_filename: jdk-8u181-linux-x64.tar.gz
    java_name: "{{download_folder}}/jdk1.8.0_181"
    java_archive: "{{download_folder}}/{{ java_filename }}"
    java_home: /usr/java/jdk1.8.0_181

  become: yes
  become_method: sudo
  tasks:
    - name: install libselinux-python
      yum:
        name: libselinux-python
        state: present
    - name: create directory
      file:
        path: /usr/java
        state: directory
        owner: root
        group: root
        mode: 0755
#   - name: create dir1
#     file: 
#       path: /opt/oracle/jdk1.8.0_181
#       state: directory
#       owner: root
#       group: root
#       mode: 0755
    - name: check for java 8 download
      stat: 
        path: "{{ java_archive }}"    
      register: java8dl
    - debug:
        msg: "{{ java8dl.stat.exists }}"
   
    - name: download java 8
      get_url: url={{ download_url }} dest={{ java_archive }} headers="Cookie:' gpw_e24=http%3A%2F%2Fwww.oracle.com%2F; oraclelicense=accept-securebackup-cookie'" validate_certs=no owner=root group=root mode=744 
      when: java8dl.stat.exists == False
    - name: unpack java archive
#     file: state=directory path={{ java_name }} owner=root group=root recurse=yes
      unarchive:
        src: "{{ java_archive }}"
        dest: /usr/java/
        remote_src: yes
    - name: update alternatives
      command: alternatives --install /usr/bin/java java {{ java_home }}/bin/java 50
    - name: check if already downloaded
      stat: 
        path: /opt/spark-2.3.1-bin-hadoop2.7.tgz
      register: spark_dl
    - debug: 
        msg: "{{ spark_dl.stat.exists }}"
    - name: download spark standalone
      get_url:
        url:  https://archive.apache.org/dist/spark/spark-2.3.1/spark-2.3.1-bin-hadoop2.7.tgz
        dest: /opt
      when: spark_dl.stat.exists == False
#   - name: copy local file to vm
#     copy:
#       src: ./files/sshpass-1.06-1.el7.x86_64.rpm
#       dest: /opt
#       owner: root
#       group: root
    - name: extract spark download
      unarchive:
        src: /opt/spark-2.3.1-bin-hadoop2.7.tgz
        dest: /opt
        remote_src: yes
    - name: pip install upgrade pip
      shell: pip install --upgrade pip
    - name: pip install pyspark
      shell: pip install pyspark

    - name: check zeppelin dl
      stat:
        path: /opt/zeppelin-0.8.0-bin-netinst.tgz
      register: zeppelin_dl
    - name: download zepellin
      get_url:
        url: http://mirror.cogentco.com/pub/apache/zeppelin/zeppelin-0.8.0/zeppelin-0.8.0-bin-netinst.tgz
        dest: /opt
      when: zeppelin_dl.stat.exists == False
    - name: unarchive zeppelin
      unarchive:
        src: /opt/zeppelin-0.8.0-bin-netinst.tgz
        dest: /opt
        remote_src: yes
      when: zeppelin_dl.stat.exists == True
    - name: install zeppelin interpreters
      command: 'sh /opt/zeppelin-0.8.0-bin-netinst/bin/install-interpreter.sh -a'
#     shell: sh /opt/zeppelin-0.8.0-bin-netinst/bin/install-interpreter.sh -a
      register: zeppelin_install
    - debug: var=zeppelin_install.stdout_lines
#   - debug: msg={{ zeppelin_install.stdout.split('\n')[:-1] }}
